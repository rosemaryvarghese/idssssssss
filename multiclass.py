# -*- coding: utf-8 -*-
"""Multiclass.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uG4JnbhGHA-L_HiW8-gk5Yvw3A6s7JgV
"""

#Importing necessary dependencies
import numpy as np
import pandas as pd
import sklearn.metrics
import sklearn.model_selection
import sklearn.linear_model
import sklearn.preprocessing
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import optimizers
from tensorflow.keras.models import Model, load_model, Sequential
from tensorflow.keras.layers import Input, Dense, Dropout, AlphaDropout
from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_recall_curve
from sklearn.metrics import recall_score, classification_report, auc, roc_curve
from sklearn.metrics import precision_recall_fscore_support, f1_score
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn import preprocessing
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
from numpy import dstack
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

from google.colab import drive
drive.mount('/content/drive')

#Loading dataset
d1 = pd.read_csv('/content/drive/MyDrive/datsets/unsw_nb15/UNSW_NB15_testing-set.csv')
t1 = pd.read_csv('/content/drive/MyDrive/datsets/unsw_nb15/UNSW_NB15_training-set.csv')

data = d1.append(t1)

data.describe()

#Dropping attack category column since problem is binary classification
data.drop(columns = 'label', inplace = True)

#Dropping NaN values
data.dropna(inplace = True)

#Checking for null values in the dataset
data.isnull().sum().sum()

data['service'].replace('-',np.nan,inplace=True)

data.isnull().sum()

data.dropna(inplace=True)

data.shape



plt.figure(figsize=(8,8))
plt.pie(data.attack_cat.value_counts(),labels=data.attack_cat.unique(),autopct='%0.2f%%')
plt.title('Pie chart distribution of multi-class labels')
plt.legend(loc='best')
plt.show()

label_feature = ['label']
categorical_features = ['proto', 'service', 'state']

drop_features = ['id', 'sttl', 'dttl', 'swin', 'dwin', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports', 'attack_cat']
numerical_features = list(set(data.columns) - set(label_feature) - set(categorical_features) - set(drop_features))

scaler = MinMaxScaler()
data[numerical_features] = scaler.fit_transform(data[numerical_features])

serv = OneHotEncoder()
pro = OneHotEncoder()
sta = OneHotEncoder()

def encode(data):

    X = serv.fit_transform(data['service'].values.reshape(-1, 1))
    X2 = pro.fit_transform(data['proto'].values.reshape(-1, 1))
    X3 = sta.fit_transform(data['state'].values.reshape(-1, 1))

    data = pd.concat([data,
                      pd.DataFrame(X2.toarray(), columns=['proto_'+i for i in pro.categories_[0]]),
                      pd.DataFrame(X.toarray(), columns=['service_'+i for i in serv.categories_[0]]),
                      pd.DataFrame(X3.toarray(), columns=['state_'+i for i in sta.categories_[0]])],
                      axis=1)

    data.drop(['proto', 'service', 'state'], axis=1, inplace=True)

    return data

data.reset_index(drop=True)

data.shape

catval = ['proto', 'service', 'state']
data_cat = data[catval].copy()
data_cat.head()

data_cat = pd.get_dummies(data_cat,columns=catval)
data = pd.concat([data, data_cat],axis=1)

data.drop(columns=catval,inplace=True)

# one-hot-encoding attack label
multi_data = data.copy()
multi_label = pd.DataFrame(multi_data.attack_cat)

multi_data = pd.get_dummies(multi_data,columns=['attack_cat'])

# label encoding (0,1,2,3,4,5,6,7,8) multi-class labels
le2 = preprocessing.LabelEncoder()
enc_label = multi_label.apply(le2.fit_transform)
multi_data['label'] = enc_label

le2.classes_

np.save("le2_classes.npy",le2.classes_,allow_pickle=True)

multi_data.label

X = data.drop(columns=['attack_cat'],axis=1)
Y = multi_data['label']

Y.value_counts()

data.attack_cat.value_counts()

X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.20, random_state=50)

#ANOVA Feature selection
def select_features(X_train, y_train, X_test):
	# configure to select a subset of features
	fs = SelectKBest(score_func=f_classif, k=15)
	# learn relationship from training data
	fs.fit(X_train, y_train)
	# transform train input data
	X_train_fs = fs.transform(X_train)
	# transform test input data
	X_test_fs = fs.transform(X_test)
	return X_train_fs, X_test_fs, fs

X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)

#Evaluation Metrics for the Multilayer Perceptrons
class FalsePositiveRate(tf.keras.metrics.Metric):
    def __init__(self, name='false_positive_rate', **kwargs):
        super(FalsePositiveRate, self).__init__(name=name, **kwargs)
        self.negatives = self.add_weight(name='negatives', initializer='zeros')
        self.false_positives = self.add_weight(name='false_negatives', initializer='zeros')
        
    def update_state(self, y_true, y_pred, sample_weight=None):
        y_true = tf.cast(y_true, tf.bool)
        
        negatives = tf.reduce_sum(tf.cast(tf.equal(y_true, False), self.dtype))
        
        self.negatives.assign_add(negatives)
        
        y_pred = tf.greater_equal(y_pred, 0.5)
        
        false_positive_values = tf.logical_and(tf.equal(y_true, False), tf.equal(y_pred, True)) 
        false_positive_values = tf.cast(false_positive_values, self.dtype)
        if sample_weight is not None:
            sample_weight = tf.cast(sample_weight, self.dtype)
            sample_weight = tf.broadcast_weights(sample_weight, values)
            values = tf.multiply(false_positive_values, sample_weight)
        
        false_positives = tf.reduce_sum(false_positive_values)
        
        self.false_positives.assign_add(false_positives)
        
    def result(self):
        return tf.divide(self.false_positives, self.negatives)

#Evaluation Metrics for the Multilayer Perceptrons
def plot_loss(model_history):
  train_loss=[value for key, value in model_history.items() if 'loss' in key.lower()][0]
  valid_loss=[value for key, value in model_history.items() if 'loss' in key.lower()][1]
  fig, ax1 = plt.subplots()
  color = 'tab:blue'
  ax1.set_xlabel('Epoch')
  ax1.set_ylabel('Loss', color=color)
  ax1.plot(train_loss, '--', color=color, label='Train Loss')
  ax1.plot(valid_loss, color=color, label='Valid Loss')
  ax1.tick_params(axis='y', labelcolor=color)
  plt.legend(loc='upper left')
  plt.title('Model Loss')
  plt.show()

#Evaluation Metrics for the Multilayer Perceptrons
def plot_model_recall_fpr(model_history):
  train_recall=[value for key, value in model_history.items() if 'recall' in key.lower()][0]
  valid_recall=[value for key, value in model_history.items() if 'recall' in key.lower()][1]
  train_fpr=[value for key, value in model_history.items() if 'false_positive_rate' in key.lower()][0]
  valid_fpr=[value for key, value in model_history.items() if 'false_positive_rate' in key.lower()][1]
  fig, ax1 = plt.subplots()
  color = 'tab:red'
  ax1.set_xlabel('Epoch')
  ax1.set_ylabel('Recall', color=color)
  ax1.set_ylim([-0.05,1.05])
  ax1.plot(train_recall, '--', color=color, label='Train Recall')
  ax1.plot(valid_recall, color=color, label='Valid Recall')
  ax1.tick_params(axis='y', labelcolor=color)
  plt.legend(loc='upper left')
  plt.title('Model Recall and FPR')
  ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis
  color = 'tab:blue'
  ax2.set_ylabel('False Positive Rate', color=color)  # we already handled the x-label with ax1
  ax2.plot(train_fpr, '--', color=color, label='Train FPR')
  ax2.plot(valid_fpr, color=color, label='Valid FPR')
  ax2.tick_params(axis='y', labelcolor=color)
  ax2.set_ylim([-0.05,1.05])
  fig.tight_layout()  # otherwise the right y-label is slightly clipped
  plt.legend(loc='upper right')
  plt.show()

#Evaluation Metrics for the Multilayer Perceptrons
def plot_train_history(history):
    # plot the cost and accuracy 
    loss_list = history['loss']
    val_loss_list = history['val_loss']
    accuracy_list = history['accuracy']
    val_accuracy_list = history['val_accuracy']
    # epochs = range(len(loss_list))

    # plot the cost
    plt.plot(loss_list, 'b', label='Training cost')
    plt.plot(val_loss_list, 'r', label='Validation cost')
    plt.ylabel('cost')
    plt.xlabel('iterations')
    plt.title('Training and validation cost')
    plt.legend()

    plt.figure()
    
    # plot the accuracy
    plt.plot(accuracy_list, 'b', label='Training accuracy')
    plt.plot(val_accuracy_list, 'r', label='Validation accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('iterations')
    plt.title('Training and validation accuracy')
    plt.legend()

#Models being used as base learners
#Model1 - 
mlp = Sequential()
mlp.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))
mlp.add(Dense(256, activation='relu'))
mlp.add(Dense(256, activation='relu'))
mlp.add(Dense(256, activation='relu'))
mlp.add(Dense(256, activation='relu'))
mlp.add(Dense(9, activation='softmax'))
mlp.summary()
mlp.compile(optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy', FalsePositiveRate(), tf.keras.metrics.Recall()]
           )

#Model2 - 
mlp2 = Sequential()
mlp2.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))
mlp2.add(Dense(256, activation='relu'))
mlp2.add(Dense(256, activation='relu'))
mlp2.add(Dense(256, activation='relu'))
mlp2.add(Dense(256, activation='relu'))
mlp2.add(Dense(9, activation='softmax'))
mlp2.summary()
mlp2.compile(optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy', FalsePositiveRate(), tf.keras.metrics.Recall()]
           )

#Model3 - 
mlp3 = Sequential()
mlp3.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))
mlp3.add(Dense(256, activation='relu'))
mlp3.add(Dense(256, activation='relu'))
mlp3.add(Dense(256, activation='relu'))
mlp3.add(Dense(256, activation='relu'))
mlp3.add(Dense(9, activation='softmax'))
mlp3.summary()
mlp3.compile(optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy', FalsePositiveRate(), tf.keras.metrics.Recall()]
           )

#Model4 - 
mlp4 = Sequential()
mlp4.add(Dense(units=128, input_dim=X_train.shape[1], activation='relu'))
mlp4.add(Dense(256, activation='relu'))
mlp4.add(Dense(256, activation='relu'))
mlp4.add(Dense(256, activation='relu'))
mlp4.add(Dense(9, activation='softmax'))
mlp4.summary()
mlp4.compile(optimizer='adam',
            loss='categorical_crossentropy',
            metrics=['accuracy', FalsePositiveRate(), tf.keras.metrics.Recall()]
           )

grid_parameters = [
    { #MLP
        'batch_size' : [1000, 500, 100],
        'epochs' : [80, 85, 90, 95, 100, 105, 110, 115, 120, 125],
        'validation_split' : [0.2],
        'verbose' : [0]
    },
    { #MLP2
        'batch_size' : [1000, 500, 100],
        'epochs' : [80, 85, 90, 95, 100, 105, 110, 115, 120, 125],
        'validation_split' : [0.2],
        'verbose' : [0]
    }, 
    { #MLP3
        'batch_size' : [1000, 500, 100],
        'epochs' : [80, 85, 90, 95, 100, 105, 110, 115, 120, 125],
        'validation_split' : [0.2],
        'verbose' : [0]
    },
    { #MLP3
        'batch_size' : [1000, 500, 100],
        'epochs' : [80, 85, 90, 95, 100, 105, 110, 115, 120, 125],
        'validation_split' : [0.2],
        'verbose' : [0]
    }
]

y_train.dtypes
X_train.dtypes

y_train = tf.keras.utils.to_categorical(y_train, 9)
history = mlp.fit(x=X_train,y=y_train,batch_size=1000,epochs=85,validation_split = 0.2).history

h2 = mlp2.fit(x=X_train,
                  y=y_train,
                  batch_size=1000,
                  epochs=118,validation_split = 0.2,
                  verbose=0).history

h3 = mlp3.fit(x=X_train,
                  y=y_train,
                  batch_size=1000,
                  epochs=90,validation_split = 0.2,
                  verbose=0).history

h4 = mlp4.fit(x=X_train,
                  y=y_train,
                  batch_size=1000,
                  epochs=75,validation_split = 0.2,
                  verbose=0).history

y_test = tf.keras.utils.to_categorical(y_test, 9)
test_results1 = mlp.evaluate(X_test, y_test, verbose=1)
print(f'Test results1 -  Accuracy: {test_results1[1]*100}')
test_results2 = mlp2.evaluate(X_test, y_test, verbose=1)
print(f'Test results2 -  Accuracy: {test_results2[1]*100}')
test_results3 = mlp3.evaluate(X_test, y_test, verbose=1)
print(f'Test results3 -  Accuracy: {test_results3[1]*100}')
test_results4 = mlp4.evaluate(X_test, y_test, verbose=1)
print(f'Test results4 -  Accuracy: {test_results4[1]*100}')

#Graphs
print("MODEL - 1")
plot_loss(history)
plot_model_recall_fpr(history)
plot_train_history(history)
print("MODEL - 2")
plot_loss(h2)
plot_model_recall_fpr(h2)
plot_train_history(h2)
print("MODEL - 3")
plot_loss(h3)
plot_model_recall_fpr(h3)
plot_train_history(h3)
print("MODEL - 4")
plot_loss(h4)
plot_model_recall_fpr(h4)
plot_train_history(h4)

mlp.save('model1.h5')

mlp2.save('model2.h5')

mlp3.save('model3.h5')

mlp4.save('model4.h5')

def load_all_models(n_models):
	all_models = list()
	for i in range(n_models):
		# Specify the filename
		filename = '/content/model' + str(i + 1) + '.h5'
		# load the model 
		model = load_model(filename,custom_objects=dependencies)
		# Add a list of all the weaker learners
		all_models.append(model)
		print('>loaded %s' % filename)
	return all_models

dependencies = {'FalsePositiveRate': FalsePositiveRate}

n_members = 4
members = load_all_models(n_members)
print('Loaded %d models' % len(members))