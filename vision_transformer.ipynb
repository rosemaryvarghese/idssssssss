{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "vision-transformer.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "_lDRq_hdAXvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "trusted": true,
        "id": "OTW8f_yiAXvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing necessary dependencies\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.linear_model\n",
        "import sklearn.preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, AlphaDropout\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve\n",
        "from sklearn.metrics import recall_score, classification_report, auc, roc_curve\n",
        "from sklearn.metrics import precision_recall_fscore_support, f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from numpy import dstack\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "trusted": true,
        "id": "qH3gPDlXAXvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "id": "WYg_mYE9AXv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    input_shape = (7,7,1)\n",
        "    learning_rate = 0.001\n",
        "    weight_decay = 0.0001\n",
        "    batch_size = 256\n",
        "    num_classes = 10\n",
        "    num_epochs = 100\n",
        "    image_size = 72\n",
        "    patch_size = 6\n",
        "    num_patches = (image_size // patch_size) ** 2\n",
        "    projection_dim = 64\n",
        "    num_heads = 4\n",
        "    transformer_units = [\n",
        "        projection_dim * 2,\n",
        "        projection_dim\n",
        "    ]\n",
        "    transformer_layers = 8\n",
        "    mlp_head_units = [2048, 1024]"
      ],
      "metadata": {
        "trusted": true,
        "id": "d-yjOLk2AXv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "Fm78Zz4NAXv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sample Images"
      ],
      "metadata": {
        "id": "oCduvjEvAXv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d1 = pd.read_csv('../input/rmv/UNSW_NB15_training-set.csv')\n",
        "t1 = pd.read_csv('../input/rmv/UNSW_NB15_testing-set.csv')"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "id": "tv6X-sjaAXv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import and preprcess dataset"
      ],
      "metadata": {
        "id": "KnkxAKz4AXv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = d1.append(t1, ignore_index = True)\n",
        "from sklearn import preprocessing\n",
        "data.drop(columns = 'label', inplace = True)\n",
        "multic = pd.DataFrame(data.attack_cat)\n",
        "le2 = preprocessing.LabelEncoder()\n",
        "enc_label = multic.apply(le2.fit_transform)\n",
        "data['attax'] = enc_label\n",
        "categorical_features = ['proto', 'service', 'state']\n",
        "label_feature = ['attack_cat', 'attax']"
      ],
      "metadata": {
        "trusted": true,
        "id": "NDKtJ9dgAXv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_features = ['id', 'sttl', 'dttl', 'swin', 'dwin', 'trans_depth', 'response_body_len', 'ct_srv_src', 'ct_state_ttl', 'ct_dst_ltm', 'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'is_ftp_login', 'ct_ftp_cmd', 'ct_flw_http_mthd', 'ct_src_ltm', 'ct_srv_dst', 'is_sm_ips_ports']\n",
        "numerical_features = list(set(data.columns) - set(label_feature) - set(categorical_features) - set(drop_features))"
      ],
      "metadata": {
        "trusted": true,
        "id": "HUyyURoLAXv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scale = StandardScaler()\n",
        "data.drop(columns = categorical_features, inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Pv5nv4sAAXv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ryKkq8xrAXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = data['attax']\n",
        "X = data.drop(columns = ['attax', 'attack_cat'], axis = 1)"
      ],
      "metadata": {
        "trusted": true,
        "id": "BCPbqyn6AXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tab2img\n",
        "from tab2img.converter import Tab2Img\n",
        "scaler = preprocessing.MinMaxScaler().fit(X)\n",
        "X_scaled_train = scaler.transform(X)\n",
        "y_scaler =  preprocessing.StandardScaler().fit(Y.values.reshape(-1, 1))\n",
        "y_scaled_train = y_scaler.transform(Y.values.reshape(-1, 1))\n",
        "model = Tab2Img()\n",
        "train_images = model.fit_transform(X_scaled_train, y_scaled_train)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pIbzwsjnAXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, optimizers\n",
        "from tensorflow.keras import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "trusted": true,
        "id": "6FWBzUW2AXv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_shape = (train_images.shape[0], train_images.shape[1], train_images.shape[2], 1)\n",
        "Y = tf.keras.utils.to_categorical(Y)\n",
        "train_images = train_images.reshape(new_shape)"
      ],
      "metadata": {
        "trusted": true,
        "id": "bSfbUoFDAXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data, train_labels, test_labels = train_test_split(train_images, Y, random_state=10, test_size=0.2)"
      ],
      "metadata": {
        "trusted": true,
        "id": "vdLHm3DVAXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(images, row_count, column_count):\n",
        "    fig, axs = plt.subplots(row_count, column_count, figsize=(10,10))\n",
        "    for i in range(row_count):\n",
        "        for j in range(column_count):\n",
        "            axs[i,j].imshow(images[i * column_count + j])\n",
        "            axs[i,j].axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "id": "pOKtLG0FAXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indices = np.random.choice(train_data.shape[0], 100)\n",
        "sample_images(train_data[indices], 10, 10)"
      ],
      "metadata": {
        "trusted": true,
        "id": "FX0s-58mAXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Development"
      ],
      "metadata": {
        "id": "MocteibsAXv4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Augmentation"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2021-10-06T17:34:43.93151Z",
          "iopub.execute_input": "2021-10-06T17:34:43.931777Z",
          "iopub.status.idle": "2021-10-06T17:34:43.939137Z",
          "shell.execute_reply.started": "2021-10-06T17:34:43.931749Z",
          "shell.execute_reply": "2021-10-06T17:34:43.938461Z"
        },
        "id": "LyiQaXOOAXv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_layer = tf.keras.Sequential([\n",
        "    keras.layers.Input(Config.input_shape),\n",
        "    keras.layers.experimental.preprocessing.Normalization(),\n",
        "    keras.layers.experimental.preprocessing.Resizing(Config.image_size, Config.image_size),\n",
        "    keras.layers.experimental.preprocessing.RandomRotation(factor=0.02),\n",
        "    keras.layers.experimental.preprocessing.RandomZoom(height_factor=0.2, width_factor=0.2),\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "id": "p1gxYk9fAXv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmentation_layer.layers[0].adapt(train_data)"
      ],
      "metadata": {
        "trusted": true,
        "id": "RkuV5At7AXv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MLP"
      ],
      "metadata": {
        "id": "mFu3G3tSAXv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "    for units in hidden_units:\n",
        "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x"
      ],
      "metadata": {
        "trusted": true,
        "id": "duczkTuHAXv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patch Creation Layer"
      ],
      "metadata": {
        "id": "TgyXpEwoAXv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        \n",
        "    def call(self, images):\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images = images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            rates=[1, 1, 1, 1],\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "        return patches"
      ],
      "metadata": {
        "trusted": true,
        "id": "zkPkXHvEAXv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "image = train_data[np.random.choice(range(train_data.shape[0]))]\n",
        "print(image.shape)\n",
        "plt.imshow(np.squeeze(image).astype(\"uint8\"))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "resized_image = tf.image.resize(\n",
        "    tf.convert_to_tensor([image]), size=(Config.image_size, Config.image_size)\n",
        ")\n",
        "print(resized_image.shape)\n",
        "patches = Patches(Config.patch_size)(resized_image)\n",
        "print(f\"Image size: {Config.image_size} X {Config.image_size}\")\n",
        "print(f\"Patch size: {Config.patch_size} X {Config.patch_size}\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "0vYpBKrvAXv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Patch Encoder Layer"
      ],
      "metadata": {
        "id": "kXoI-7fOAXv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(layers.Layer):\n",
        "    \n",
        "    def __init__(self, num_patches, projection_dim):\n",
        "        super(PatchEncoder, self).__init__()\n",
        "        self.num_patches = num_patches\n",
        "        self.projection = layers.Dense(projection_dim)\n",
        "        self.position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=projection_dim\n",
        "        )\n",
        "    def call(self, patch):\n",
        "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
        "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "        return encoded\n",
        "        "
      ],
      "metadata": {
        "trusted": true,
        "id": "5rzfmR_wAXv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Model"
      ],
      "metadata": {
        "id": "6JPEBrK3AXv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vision_transformer():\n",
        "    # Inputs\n",
        "    inputs = layers.Input(shape=Config.input_shape)\n",
        "    # Data Augmentation\n",
        "    augmented = augmentation_layer(inputs)\n",
        "    # Patches\n",
        "    patches = Patches(Config.patch_size)(augmented)\n",
        "    encoder_patches = PatchEncoder(Config.num_patches, Config.projection_dim)(patches)\n",
        "    \n",
        "    for _ in range(Config.transformer_layers):\n",
        "        # Layer Normalization 1\n",
        "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoder_patches)\n",
        "        # Multi-Head Attention Layer\n",
        "        attention_output = layers.MultiHeadAttention(\n",
        "            num_heads=Config.num_heads, \n",
        "            key_dim=Config.projection_dim,\n",
        "            dropout=0.2\n",
        "        )(x1, x1)\n",
        "        # Skip Connnection 1\n",
        "        x2 = layers.Add()([attention_output, encoder_patches])\n",
        "        \n",
        "        # Layer Normalization 2\n",
        "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "        \n",
        "        # MLP\n",
        "        x3 = mlp(x3, hidden_units=Config.transformer_units, dropout_rate=0.2)\n",
        "        \n",
        "        # Skip Connnection 2\n",
        "        encoder_patches = layers.Add()([x3, x2])\n",
        "    \n",
        "    representation = layers.LayerNormalization(epsilon=1e-6)(encoder_patches)\n",
        "    representation = layers.Flatten()(representation)\n",
        "    representation = layers.Dropout(0.5)(representation)\n",
        "    \n",
        "    features = mlp(representation, hidden_units=Config.mlp_head_units, dropout_rate=0.5)\n",
        "    \n",
        "    outputs = layers.Dense(Config.num_classes)(features)\n",
        "    \n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "trusted": true,
        "id": "G9I-sZ_VAXv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "vit_classifier = create_vision_transformer()\n",
        "vit_classifier.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "TnCZg5bbAXv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "JhVTcI_7AXv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tfa.optimizers.AdamW(\n",
        "    learning_rate=Config.learning_rate,\n",
        "    weight_decay=Config.weight_decay\n",
        ")\n",
        "vit_classifier.compile(\n",
        "    loss=keras.losses.CategoricalCrossentropy(),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "checkpoint_path = \"model.h5\"\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor=\"val_accuracy\",\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "id": "_mJ_s_mzAXv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = vit_classifier.fit(train_data, train_labels, epochs=30, batch_size= 500, validation_split = 0.2, callbacks=[checkpoint])"
      ],
      "metadata": {
        "trusted": true,
        "id": "gjL931PHAXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "metadata": {
        "trusted": true,
        "id": "-QCPYB8HAXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results1 = vit_classifier.evaluate(test_data, test_labels, verbose=1)\n",
        "print(f'Test results1 -  Accuracy: {test_results1[1]*100}')"
      ],
      "metadata": {
        "trusted": true,
        "id": "E1NdX7xxAXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ps36pxKSAXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w7W7I-CPAXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TIgkRpY1AXv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UyR4XWsfAXv7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}